library(tidyverse)
library(cluster)
library(factoextra)
data("USArrests")
head("USArrests")
data(USArrests)
head(USArrests)
df
df <- USArrests
df <- USArrests
df <- na.omit(df)
df <- scale(df)
df
K2 <- kmeans(df, centers = 2, nstart = 25)
k2 <- kmeans(df, centers = 2, nstart = 25)
str(k2)
fviz_cluster(k2, data = df)
head(df)
k2 <- kmeans(df, centers = 3, nstart = 25)
str(k2)
fviz_cluster(k2, data = df)
k2 <- kmeans(df, centers = 4, nstart = 25)
str(k2)
fviz_cluster(k2, data = df)
k2 <- kmeans(df, centers = 6, nstart = 25)
str(k2)
fviz_cluster(k2, data = df)
k2 <- kmeans(df, centers = 2, nstart = 25)
str(k2)
fviz_cluster(k2, data = df)
#Gonna try this with 3,4,5 clusters
df %>% as_tibble %>% mutate(cluster = k2$cluster,
state = row.names(USArrests)) %>% ggplot(aes(UrbanPop, Murder,
color = factor(cluster), label = state)) + geom_text()
#Gonna try this with 3,4,5 clusters
#doing some visualization
df %>% as_tibble %>% mutate(cluster = k2$cluster,
state = row.names(USArrests)) %>% ggplot(aes(UrbanPop, Murder,
color = factor(cluster), label = state)) + geom_text()
```k3 <- kmeans(df, centers = 3, nstart = 25)
k3 <- kmeans(df, centers = 3, nstart = 25)
k4 <- kmeans(df, centers = 4, nstart = 25)
k5 <- kmeans(df, centers = 5, nstart = 25)
pl <- fviz_cluster(k2, geom = 'point', data = df) + ggtitle('k = 2)
p2 <- fviz_cluster(k3, geom = 'point', data = df) + ggtitle('k = 3)
pl <- fviz_cluster(k2, geom = 'point', data = df) + ggtitle('k = 2')
p2 <- fviz_cluster(k3, geom = 'point', data = df) + ggtitle('k = 3')
p3 <- fviz_cluster(k4, geom = 'point', data = df) + ggtitle('k = 4')
p4 <- fviz_cluster(k5, geom = 'point', data = df) + ggtitle('k = 5')
k3 <- kmeans(df, centers = 3, nstart = 25)
k4 <- kmeans(df, centers = 4, nstart = 25)
k5 <- kmeans(df, centers = 5, nstart = 25)
pl <- fviz_cluster(k2, geom = 'point', data = df) + ggtitle('k = 2')
p2 <- fviz_cluster(k3, geom = 'point', data = df) + ggtitle('k = 3')
p3 <- fviz_cluster(k4, geom = 'point', data = df) + ggtitle('k = 4')
p4 <- fviz_cluster(k5, geom = 'point', data = df) + ggtitle('k = 5')
fviz_cluster(k3, data = df)
#pl <- fviz_cluster(k2, geom = 'point', data = df) + ggtitle('k = 2')
#p2 <- fviz_cluster(k3, geom = 'point', data = df) + ggtitle('k = 3')
#p3 <- fviz_cluster(k4, geom = 'point', data = df) + ggtitle('k = 4')
#p4 <- fviz_cluster(k5, geom = 'point', data = df) + ggtitle('k = 5')
fviz_cluster(k3, data = df)
fviz_cluster(k4, data = df)
#pl <- fviz_cluster(k2, geom = 'point', data = df) + ggtitle('k = 2')
#p2 <- fviz_cluster(k3, geom = 'point', data = df) + ggtitle('k = 3')
#p3 <- fviz_cluster(k4, geom = 'point', data = df) + ggtitle('k = 4')
#p4 <- fviz_cluster(k5, geom = 'point', data = df) + ggtitle('k = 5')
fviz_cluster(k2, data = df)
fviz_cluster(k3, data = df)
fviz_cluster(k4, data = df)
fviz_cluster(k5, data = df)
#pl <- fviz_cluster(k2, geom = 'point', data = df) + ggtitle('k = 2')
#p2 <- fviz_cluster(k3, geom = 'point', data = df) + ggtitle('k = 3')
#p3 <- fviz_cluster(k4, geom = 'point', data = df) + ggtitle('k = 4')
#p4 <- fviz_cluster(k5, geom = 'point', data = df) + ggtitle('k = 5')
fviz_nbclust(df, kmeans, method = 'wss')
#using elbow method to get optimal number of clusters
fviz_nbclust(df, kmeans, method = 'wss') + geom_vline(xintercept = 4, linetype = 2)
fviz_nbclust(df, kmeans, method = 'wss') + geom_vline(xintercept = 4, linetype = 2)
#silhouette method
#refers to a method of interpretation and validation of consistency within clusters of data of data. This specific technique This specific technique provides a clear and succinct graphical representation of how well each object has been classified.  The silhouette value is a measure of how similar an object is to its own cluster (cohesian) compared to other clusters (se peration. The silhouettes range from [-1,1] such that high values indicate that the neighboring clusters ). If most objects have a high value, then the clustering configuration is ideal/appropriate. If many points have a low or negative value, then the custering configuration may have too many or too few clusters. Silhouette can be calculated with any any metric.
fviz_nbclust(df, kmeans, method = 'Silhouette')
fviz_nbclust(df, kmeans, method = 'silhouette')
#GAP statistics method
#The GAP statistics method can be done with any clustering method, such as k-means and hierarchical clustering. Compares the total inter-class variation for different k-values that you're going to set and also their expected values under the null reference distribution of data (no obvious clustering)
set.seed(200)
gap_stat <- clustGap(df, FUN = kmeans, nstart = 25, K.max = 10, B = 50)
#GAP statistics method
#The GAP statistics method can be done with any clustering method, such as k-means and hierarchical clustering. Compares the total inter-class variation for different k-values that you're going to set and also their expected values under the null reference distribution of data (no obvious clustering)
set.seed(200)
gap_stat <- clusGap(df, FUN = kmeans, nstart = 25, K.max = 10, B = 50)
#B = 50: null reference distribution set to 50
#k.max = 10: number of clusters
#print the resutls
print(gap_stat, method = "firstmax")
fviz_gap_stat(gap_stat)
#compute k means clustering w k = 4
fviz_cluster(k4, data = df)
install.packages("arules")
install.packages("arulesViz")
library(arules)
library(arulesViz)
?groceries
data("Groceries")
summary Groceries
data("Groceries")
summary(Groceries)
rule1 <- apriori(Groceries, parameter = lift(support= 0.002, confidence = 0.5))
rule1 <- apriori(Groceries, parameter = list(support= 0.002, confidence = 0.5))
inspect(head(rule1,5))
inspect(head(sort(rule1, by = "lift"), 5))
plot(rule1)
plot(rule1, method = 'grouped')
rule2 <- apriori(Groceries, parameter = list(support = 0.002), confidence = 0.5, minlen =5)
rule2 <- apriori(Groceries, parameter = list(support = 0.002), confidence = 0.5, minlen =5)
inspect(head(rule2,4))
plot(rule2, method = "grouped")
rule2 <- apriori(Groceries, parameter = list(support = 0.002), confidence = 0.5, minlen =4)
inspect(head(rule2,4))
plot(rule2, method = "grouped")
options(digits=3)
set.seed(1)
library(tidyverse)
library(dslabs)
install.packages("dslabs")
options(digits=3)
set.seed(1)
library(tidyverse)
install.packages("dslabs")
library(dslabs)
ds_theme_set()
n <- 1
tmp <- data.frame(outcome("?",n), feature_1 = paste0("x_1"), feature_2 = paste0("x_2"), feature_3 = paste0("x_3"), feature_4 = paste0("x_4"), feature_5 = paste0("x_5") ))
n <- 1
tmp <- data.frame(outcome=rep("?",n), feature_1 = paste0("x_1"), feature_2 = paste0("x_2"), feature_3 = paste0("x_3"), feature_4 = paste0("x_4"), feature_5 = paste0("x_5") )
n <- 1
tmp <- data.frame(outcome=rep("?",n), feature_1 = paste0("x_1"), feature_2 = paste0("x_2"), feature_3 = paste0("x_3"), feature_4 = paste0("x_4"), feature_5 = paste0("x_5") )
tmp %>% knitr::kable(align="c")
?knitr
n <- 10
tmp <- data.frame(outcome = paste0("Y,1:n"), feature_1 = paste0("X_", 1:n, 1), feature_2 = paste0("X_", 1:n, 2), feature_3 = paste0("X_", 1:n, 3), feature_4 = paste0("X_", 1:n, 4), feature_5 = paste0("X_", 1:n, 5))
n <- 10
tmp <- data.frame(outcome = paste0("Y,1:n"), feature_1 = paste0("X_", 1:n, 1), feature_2 = paste0("X_", 1:n, 2), feature_3 = paste0("X_", 1:n, 3), feature_4 = paste0("X_", 1:n, 4), feature_5 = paste0("X_", 1:n, 5))
tmp %>% knitr::kable()
knitr::include_graphics("https://d79i1fxsrar4t.cloudfront.net/assets/img/docs/zip-code-digits.47d1a727.png")
url <- "https://raw.githubusercontent.com/datasciencelabs/data/master/hand-written-digits-train.csv"
digits <- read_csv(url)
tmp <- lapply( c(1,4,5), function(i){
expand.grid(Row=1:28, Column=1:28) %>%
mutate(id=i, label=digits$label[i],
value = unlist(digits[i,-1]))
})
tmp <- Reduce(rbind, tmp)
tmp %>% ggplot(aes(Row, Column, fill=value)) +
geom_raster() +
scale_y_reverse() +
scale_fill_gradient(low="white", high="black") +
facet_grid(.~label)
tmp %>% ggplot(aes(Row,Column, fill = value)) + geom_point(pch = 21) + scale_y_reverse() + scale_fill_gradient(low = "white", high = "black") + facet_grid(.,~label)
tmp %>% ggplot(aes(Row,Column, fill = value)) + geom_point(pch = 21) + scale_y_reverse() + scale_fill_gradient(low = "white", high = "black") + facet_grid(.~label)
library(dslabs)
data(heights)
y <- heights$sex
x <- heights$height
y
x
library(dslabs)
data(heights)
set.seed(1)
N <-length(y)
y_hat <- sample(c("Male", "Female"), N, replace = TRUE)
table(predicted = y_hat, actual = y)
mean(y_hat == y)
heights %>% group_by(sex) %>% summarize(mean(height), sd(height))
inital_pubchem_data.head()
head(inital_pubchem_data)
inital_pubchem_data <- read.csv('.\pub_chem_1000_compounds.csv')
inital_pubchem_data <- read.csv('pub_chem_1000_compounds.csv')
inital_pubchem_data <- read.csv('.\\pub_chem_1000_compounds.csv')
#inital_pubchem_data <- read.csv('.\\pub_chem_1000_compounds.csv')
inital_pubchem_data <- read.csv("C:\Users\jonat_od7omk3\Desktop\CSCI_5622\project\pub_chem_1000_compounds.csv")
#inital_pubchem_data <- read.csv('.\\pub_chem_1000_compounds.csv')
inital_pubchem_data <- read.csv("C:\\Users\jonat_od7omk3\Desktop\CSCI_5622\project\pub_chem_1000_compounds.csv")
#inital_pubchem_data <- read.csv('.\\pub_chem_1000_compounds.csv')
inital_pubchem_data <- read.csv("C:\\Users\\jonat_od7omk3\Desktop\\CSCI_5622\\project\\pub_chem_1000_compounds.csv")
print(head(inital_pubchem_data))
inital_pubchem_data
inital_pubchem_data <- read.csv("C:\\Users\\jonat_od7omk3\\Desktop\\CSCI_5622\\project\\pub_chem_1000_compounds.csv")
print(x)
print(yx)
setwd("C:/Users/jonat_od7omk3/Desktop/CSCI_5622/project")
print(yx)
print("hello")
source("C:/Users/jonat_od7omk3/Desktop/CSCI_5622/project/hierch_clustering_r.R")
print(v_test)
v_test <- "hello"
print(v_test)
knitr::opts_chunk$set(echo = TRUE)
plot(hc.out_num_common_el_data)
summary(cars)
plot(pressure)
test <- "hello"
inital_pubchem_data <- read.csv("C:\\Users\\jonat_od7omk3\\Desktop\\CSCI_5622\\project\\pub_chem_1000_compounds.csv")
#get only the columns with number of carbons, hydrogens, oxygens and nitrogens
num_common_el <- inital_pubchem_data[7:10]
head(num_common_el)
num_common_el_data_std <- scale(num_common_el) #if you don't do the previous two steps before using hclust, the data isn't the correct data type (it needs to be a "dissimilarity matrix")
num_common_el_data.dist <- dist(num_common_el_data_std)
hc.out_num_common_el_data <- hclust(num_common_el_data.dist, method = "complete")
hc.out_num_common_el_data
plot(hc.out_num_common_el_data)
rect.hclust(hc.out_num_common_el_data, k=3, border = 2:5)
